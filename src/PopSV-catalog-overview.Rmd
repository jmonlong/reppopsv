---
title: CNV catalog overview
author: Jean Monlong
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, tidy=TRUE)
```

# CNV catalog overview

## Load packages, functions and data

```{r libfun}
library(dplyr)
library(magrittr)
library(ggplot2)
library(tidyr)
library(GenomicRanges)
library(knitr)
library(broom)
library(PopSV)

winsor <- function(x, u=NULL, l=NULL){
  if(!is.null(u) & any(x>u)) x[x>u] = u
  if(!is.null(l) & any(x<l)) x[x<l] = l
  x
}
olProp <- function(qgr, sgr){
  sgr = reduce(sgr)
  ol = findOverlaps(qgr, sgr) %>% as.data.frame %>% mutate(qw=width(qgr)[queryHits], qsw=width(pintersect(qgr[queryHits], sgr[subjectHits]))) %>% group_by(queryHits) %>% summarize(prop=sum(qsw/qw))
  res = rep(0, length(qgr))
  res[ol$queryHits] = ol$prop
  res
}
NB.CORES=3
```

## PopSV CNVs

```{r cnv}
cnv.df = read.table('../data/CNV-PopSV-Twin_CageKid_GoNL-germline.tsv', as.is=TRUE, header=TRUE)
cnv.df %<>% mutate(project=ifelse(grepl('gonl', sample), 'GoNL', 'Twins'), project=ifelse(grepl('ck', sample), 'CageKid', project))
```

## Low-mappability calls in the population

```{r lowmap}
load('../data/twins-coverage-tracks-5kbp.RData')
extlowmap.gr = ns.df %>% filter(cov.class2=='extremely low') %>% makeGRangesFromDataFrame
lowmap.gr = ns.df %>% filter(cov.class=='low') %>% makeGRangesFromDataFrame
cnv.df$extlowmap.prop = cnv.df %>% makeGRangesFromDataFrame %>% olProp(extlowmap.gr)
cnv.df$lowmap.prop = cnv.df %>% makeGRangesFromDataFrame %>% olProp(lowmap.gr)
cnv.df %<>% mutate(extlowmap=extlowmap.prop>=.9, lowmap=lowmap.prop>=.9, type=ifelse(cn<2, 'DEL', 'DUP'))
```

## CNV catalog

```{r popsvcat, cache=TRUE}
compAllNumbers <- function(reg.df){
  sizeGenFun <- function(df){
    df %>% makeGRangesFromDataFrame %>% reduce %>% width %>% sum / 1e6
  }
  sampleSumFun <- function(df){
    data.frame(nb=nrow(df), nb.lm=sum(df$extlowmap), mb=sizeGenFun(df), nb.less3kb=sum(df$size.kb<3))
  }
  reg.df %<>% mutate(size.kb=(end-start+1)/1e3)
  ## samp.df = reg.df %>% group_by(sample) %>% do(sampleSumFun(.))
  samp.df = reg.df %>% group_by(sample) %>% summarize(nb=n(), nb.lm=sum(extlowmap), nb.less3kb=sum(size.kb<3), mb=sum(size.kb/1e3))
  data.frame(sample=length(unique(reg.df$sample)),
             nb.calls=nbCallCollapsed(reg.df),
             nb.calls.samp=mean(samp.df$nb),
             nb.lm.samp=mean(samp.df$nb.lm),
             mean.size.kb=mean(reg.df$size.kb),
             prop.less3kb=mean(reg.df$size.kb<3),
             nb.less3kb.samp=mean(samp.df$nb.less3kb),
             gen.mb=sizeGenFun(reg.df),
             gen.mb.min=min(samp.df$mb),
             gen.mb.samp=mean(samp.df$mb),
             gen.mb.max=max(samp.df$mb))
}

nbCallCollapsed <- function(reg.df, chunk.size=5e4){
  reg.gr = makeGRangesFromDataFrame(reg.df)
  nbCallCollapsed.chunk <- function(gr, all.gr){
    findOverlaps(gr, all.gr) %>% as.data.frame %>% mutate(qsw=width(pintersect(gr[queryHits], all.gr[subjectHits])), qw=width(gr[queryHits]), sw=width(all.gr[subjectHits])) %>% filter(qsw/sw>.5, qsw/qw>.5) %>% group_by(queryHits) %>% summarize(weight=1/n()) %>% .$weight %>% sum
  }
  res = tapply(1:length(reg.gr), cut(1:length(reg.gr), 1+ceiling(length(reg.gr)/chunk.size)), function(ii) nbCallCollapsed.chunk(reg.gr[ii], reg.gr))
  res %>% unlist %>% sum %>% round
}
sum.df = rbind(
    cnv.df %>% filter(project=='Twins') %>% compAllNumbers %>% mutate(project='Twins', type='all'),
    cnv.df %>% filter(project=='Twins' & type=='DEL') %>% compAllNumbers %>% mutate(project='Twins', type='DEL'),
    cnv.df %>% filter(project=='Twins' & type=='DUP') %>% compAllNumbers %>% mutate(project='Twins', type='DUP'),
    cnv.df %>% filter(project=='CageKid') %>% compAllNumbers %>% mutate(project='CageKid', type='all'),
    cnv.df %>% filter(project=='CageKid' & type=='DEL') %>% compAllNumbers %>% mutate(project='CageKid', type='DEL'),
    cnv.df %>% filter(project=='CageKid' & type=='DUP') %>% compAllNumbers %>% mutate(project='CageKid', type='DUP'),
    cnv.df %>% filter(project=='GoNL') %>% compAllNumbers %>% mutate(project='GoNL', type='all'),
    cnv.df %>% filter(project=='GoNL' & type=='DEL') %>% compAllNumbers %>% mutate(project='GoNL', type='DEL'),
    cnv.df %>% filter(project=='GoNL' & type=='DUP') %>% compAllNumbers %>% mutate(project='GoNL', type='DUP'))

sum.df %>% select(project, type, everything()) %>% kable(digits=2)

merge.sum = rbind(
    cnv.df %>% filter(project %in% c('Twins', 'CageKid')) %>% compAllNumbers %>% mutate(project='Twins & CageKid', type='all'),
    cnv.df %>% filter(project %in% c('Twins', 'CageKid'), type=='DEL') %>% compAllNumbers %>% mutate(project='Twins & CageKid', type='DEL'),
    cnv.df %>% filter(project %in% c('Twins', 'CageKid'), type=='DUP') %>% compAllNumbers %>% mutate(project='Twins & CageKid', type='DUP'),
    cnv.df %>% compAllNumbers %>% mutate(project='All', type='all'),
    cnv.df %>% filter(type=='DEL') %>% compAllNumbers %>% mutate(project='All', type='DEL'),
    cnv.df %>% filter(type=='DUP') %>% compAllNumbers %>% mutate(project='All', type='DUP'))

merge.sum %>% select(project, type, everything()) %>% kable(digits=2)
```

On average in the individuals from the Twins dataset and the normals from the CageKid dataset, `r round(merge.sum$gen.mb.samp,2)` Mb of the genome is affected per sample.

## 1000 Genomes Project CNV catalog

```{r tgpcat}
load('../data/tgp-CNV-noX-noCNV.RData')
tgp.comp = subset(tgp, svsize>300 & prop<.8)
tgp.comp$extlowmap.prop = olProp(tgp.comp, extlowmap.gr)
tgp.comp$extlowmap = tgp.comp$extlowmap.prop >= .9
```

```{r tgpcattable, cache=TRUE}
nbCallCollapsed <- function(reg.gr){
  reg.gr %>% as.data.frame %>% select(seqnames, start, end) %>% unique %>% nrow
}
sum.tgp.df = rbind(
    tgp.comp %>% as.data.frame %>% compAllNumbers %>% mutate(project='1000GP', type='all'),
    tgp.comp %>% as.data.frame %>% filter(type=='DEL') %>% compAllNumbers %>% mutate(project='1000GP', type='DEL'),
    tgp.comp %>% as.data.frame %>% filter(type=='DUP') %>% compAllNumbers %>% mutate(project='1000GP', type='DUP'))
    
sum.tgp.df %>% select(project, type, everything()) %>% kable(digits=2)

prop.gain = merge.sum$gen.mb.samp / subset(sum.tgp.df, type=='all')$gen.mb.samp - 1
```

On average per sample, there is `r round(prop.gain[1]*100,2)`% more of the genome affected in PopSV catalog (in term of CNVs larger than 300 bp).

## Frequency distribution

```{r freq, cache=TRUE}
## Remove related samples in the Twins dataset
load("../data/twins-5kbp-files.RData")
twins = files.df %>% filter(grepl('Twin', ped)) %>% select(sample, ped)
cnv.ur = subset(cnv.df, !(sample %in% twins$sample))
nb.samp.ur = cnv.ur$sample %>% unique %>% length

## Cumulative proportion
cnv.dd = cnv.ur %>% group_by(type) %>% do(freq.range(.)) %>% mutate(prop=round(prop,4)) %>% group_by(type, nb, prop) %>% summarize(kb=sum((end-start+1)/1e3))
tgp.subsamps = tgp.comp$sample %>% unique %>% sample(nb.samp.ur)
tgp.dd = tgp.comp %>% as.data.frame %>% dplyr::rename(chr=seqnames) %>% filter(sample %in% tgp.subsamps) %>% group_by(type) %>% do(freq.range(.)) %>% mutate(prop=round(prop,4)) %>% group_by(type, nb, prop) %>% summarize(kb=sum((end-start+1)/1e3))
cumfreq.popsv.tgp = rbind(data.frame(set="PopSV", cnv.dd), data.frame(set="1000GP", tgp.dd)) %>% group_by(set, type) %>% arrange(desc(prop)) %>% mutate(prop.gen=kb/sum(kb), cumprop=cumsum(prop.gen))

cumfreq.popsv.tgp %>% filter(!is.na(type)) %>% ggplot(aes(x=prop, y=cumprop,colour=type, linetype=set)) + geom_line(alpha=.9, size=2) + theme_bw() + ylim(0,1) + xlab("frequency") + ylab("cumulative proportion") + theme(legend.position=c(.99,.99),legend.justification=c(1,1)) + scale_colour_brewer(name="", palette="Set1") + scale_x_log10(breaks=c(.002,.005,.01,.02,.05,.1,.2,.5))
```

## CNV catalogs from GenomeSTRiP

```{r gscat}
load('../data/GenomeSTRiP-CNVcatalogs-Handsaker2016-Chiang2018.RData')

gs.hand$extlowmap.prop = olProp(gs.hand, extlowmap.gr)
gs.hand$extlowmap = gs.hand$extlowmap.prop >= .9

chiang.tot.samp = 148
gs.chiang.samp = lapply(1:chiang.tot.samp, function(ii){
  var = runif(nrow(gs.chiang))
  res = gs.chiang[which(var<gs.chiang$NSAMP/chiang.tot.samp),]
  res$sample = paste0('s', ii)
  res
})
gs.chiang.samp = do.call(rbind, gs.chiang.samp)
gs.chiang.samp = makeGRangesFromDataFrame(gs.chiang.samp, keep.extra.columns=TRUE)
gs.chiang.samp$extlowmap.prop = olProp(gs.chiang.samp, extlowmap.gr)
gs.chiang.samp$extlowmap = gs.chiang.samp$extlowmap.prop >= .9

sum.gs.df = rbind(
  gs.hand %>% as.data.frame %>% compAllNumbers %>% mutate(project='GenomeSTRiP (Handsaker 2016)', type='all'),
  gs.hand %>% as.data.frame %>% filter(type=='DEL') %>% compAllNumbers %>% mutate(project='GenomeSTRiP (Handsaker 2016)', type='DEL'),
  gs.hand %>% as.data.frame %>% filter(type=='DUP') %>% compAllNumbers %>% mutate(project='GenomeSTRiP (Handsaker 2016)', type='DUP'),
  gs.chiang.samp %>% as.data.frame %>% compAllNumbers %>% mutate(project='GenomeSTRiP (Chiang 2018)', type='all'))
    
sum.gs.df %>% dplyr::select(project, type, everything()) %>% kable(digits=2)
```

## CNV catalog from GoNL

```{r gonlcat}
load('../data/GoNL-CNVs.RData')
gonl.cnv = subset(gonl.cnv, width(gonl.cnv)>300 & prop<.8)

gonl.tot.samp = 750
gonl.samp = lapply(1:gonl.tot.samp, function(ii){
  var = runif(length(gonl.cnv))
  res = gonl.cnv[which(var<gonl.cnv$prop)]
  res$sample = paste0('s', ii)
  res
})
gonl.samp = do.call(c, gonl.samp)
gonl.samp$extlowmap.prop = olProp(gonl.samp, extlowmap.gr)
gonl.samp$extlowmap = gonl.samp$extlowmap.prop >= .9

sum.gonl.df = rbind(
  gonl.samp %>% as.data.frame %>% compAllNumbers %>% mutate(project='GoNL', type='all'),
  gonl.samp %>% as.data.frame %>% filter(type=='DEL') %>% compAllNumbers %>% mutate(project='GoNL', type='DEL'),
  gonl.samp %>% as.data.frame %>% filter(type=='DUP') %>% compAllNumbers %>% mutate(project='GoNL', type='DUP'))

sum.gonl.df %>% dplyr::select(project, type, everything()) %>% kable(digits=2)
```


## Comparison with long-read-based catalogs

### Chaisson et al

```{r chaissonlrcat, cache=TRUE}
load('../data/sv.chaisson.RData')
sv.chaisson = subset(sv.chaisson, chr %in% 1:22)
sv.chaisson.gr = makeGRangesFromDataFrame(sv.chaisson)

## Collapsed CNVs
reduceDF <- function(df){
  df %>% makeGRangesFromDataFrame %>% reduce %>% as.data.frame
}
tgp.col = tgp %>% as.data.frame %>% dplyr::select(-sample, -CN) %>% unique %>% filter(type %in% c('DEL','DUP')) %>% group_by(type) %>% do(reduceDF(.)) %>% makeGRangesFromDataFrame(keep.extra.columns=TRUE)
popsv.col = cnv.df %>% dplyr::select(chr, start, end, type) %>% unique %>% group_by(type) %>% do(reduceDF(.)) %>% makeGRangesFromDataFrame(keep.extra.columns = TRUE)
## Merge catalogs
catalogs = list(PopSV=popsv.col, '1000GP'=tgp.col)

## Create subsets for each catalog: all calls, loss only, gain only, low-map, extremely low map.
cat.l = lapply(catalogs, function(cat.gr){
  list(all= cat.gr,
       loss = cat.gr[which(cat.gr$type=="DEL")],
       gain = cat.gr[which(cat.gr$type=="DUP")],
       lm = cat.gr[overlapsAny(cat.gr, lowmap.gr)],
       elm = cat.gr[overlapsAny(cat.gr, extlowmap.gr)])
})

## Enrichment analysis
testOlLR <- function(gr, feat.grl, cat.list){
  ## This function draws control regions that fit the distribution of 'gr', controlling for 'feat.grl' features, and compute the overlap with each catalog/subset in 'cat.list'.
  cont.gr = draw.controls(gr, feat.grl, nb.cores=1)
  var.ol = lapply(names(cat.list), function(cat.name){
    res = lapply(names(cat.list[[cat.name]]), function(set.name) {
                                        # mean(overlapsAny(gr, cont.gr)))
      df = rbind(data.frame(region=TRUE, ol = overlapsAny(cat.l[[cat.name]][[set.name]], gr)),
                 data.frame(region=FALSE, ol = overlapsAny(cat.l[[cat.name]][[set.name]], cont.gr)))
      glm(ol~region, data=df, family=binomial()) %>% tidy %>% mutate(catalog=cat.name, set=set.name)
    })
    do.call(rbind, res)
  })
  do.call(rbind, var.ol)
}

load('../data/centelgap.RData')
chaisson.enr.df = lapply(1:50, function(ii){
  testOlLR(sv.chaisson.gr, list(ctg=centelgap), cat.l)
})
chaisson.enr.df = do.call(rbind, chaisson.enr.df)
chaisson.enr.df %<>% mutate(region=factor(set, levels=c("all", "loss", "gain", "lm", "elm"), label=c( "all", "deletion", "duplication", "low-map", "ext. low-map")))
```

```{r chaissongraph}
chaisson.enr.s = chaisson.enr.df %>% filter(term=='regionTRUE') %>% group_by(region, catalog) %>% summarize(estimate=median(estimate))
chaisson.enr.df %>% filter(term=='regionTRUE') %>% ggplot(aes(x=catalog, y=estimate)) + geom_bar(aes(fill=catalog), data=chaisson.enr.s, stat='identity', position='dodge') + geom_boxplot(alpha=0, position=position_dodge(.9)) + theme_bw() + coord_flip() + ylab("logistic regression estimate (log odds ratio)") + xlab("") + theme(strip.text.y=element_text(angle=0)) + facet_grid(region~.) + guides(fill=FALSE)
chaisson.enr.s %>% kable
```


### Pendleton et al

```{r pendlrcat, cache=TRUE}
if(!file.exists('../data/NA12878.sorted.vcf.gz')){
  download.file('ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/NA12878/NA12878_PacBio_MtSinai/NA12878.sorted.vcf.gz', '../data/NA12878.sorted.vcf.gz')
}
pend.sv = read.table('../data/NA12878.sorted.vcf.gz')
pend.sv = pend.sv[,c(1,2,5,7,8,10)]
colnames(pend.sv) = c('chr','start','type','filter','info','gt')
pend.sv %<>% mutate(chr=gsub('chr','',chr), end=as.numeric(gsub('.*;END=([^;]*);.*', '\\1', info))) %>% makeGRangesFromDataFrame

pend.enr.df = lapply(1:50, function(ii){
  testOlLR(pend.sv, list(ctg=centelgap), cat.l)
})
pend.enr.df = do.call(rbind, pend.enr.df)
pend.enr.df %<>% mutate(region=factor(set, levels=c("all", "loss", "gain", "lm", "elm"), label=c( "all", "deletion", "duplication", "low-map", "ext. low-map")))
```

```{r pendgraph}
pend.enr.s = pend.enr.df %>% filter(term=='regionTRUE') %>% group_by(region, catalog) %>% summarize(estimate=median(estimate))
pend.enr.df %>% filter(term=='regionTRUE') %>% ggplot(aes(x=catalog, y=estimate)) + geom_bar(aes(fill=catalog), data=pend.enr.s, stat='identity', position='dodge') + geom_boxplot(alpha=0, position=position_dodge(.9)) + theme_bw() + coord_flip() + ylab("logistic regression estimate (log odds ratio)") + xlab("") + theme(strip.text.y=element_text(angle=0)) + facet_grid(region~.) + guides(fill=FALSE)
pend.enr.s %>% kable
```

## Novel CNV regions

```{r novel}
cnv.ur %<>% freq.range(annotate.only=TRUE)
cnv.ur$tgp.ol = cnv.ur %>% makeGRangesFromDataFrame %>% overlapsAny(reduce(tgp))
novel.reg = cnv.ur %>% filter(prop>.01, !tgp.ol) %>% makeGRangesFromDataFrame %>% reduce
ol = cnv.ur %>% makeGRangesFromDataFrame %>% findOverlaps(novel.reg) %>% as.data.frame %>% mutate(sample=cnv.ur$sample[queryHits]) %>% group_by(subjectHits) %>% summarize(nb=length(unique(sample)))
novel.reg$count = 0
novel.reg$count[ol$subjectHits] = ol$nb
novel.reg$freq = novel.reg$count / length(unique(cnv.ur$sample))
novel.reg %>% as.data.frame %>% select(-width, -strand) %>% write.table(file='../data/CNV-novel-notTGP.tsv', row.names=FALSE, quote=FALSE, sep='\t')
```

Cumulative number of novel region versus the frequency in the PopSV catalog.

```{r novelcs}
novel.reg.cs = novel.reg %>% as.data.frame %>% arrange(count) %>% mutate(region=rev(1:n())) %>% group_by(count, freq) %>% summarize(region=max(region))
novel.reg.cs %>% head %>% kable
ggplot(novel.reg.cs, aes(x=winsor(count,300), y=region)) + geom_line() + theme_bw() + ylab('cumulative number of novel CNV region') + xlab('number of affected individual (winsorized at 300)') + scale_x_continuous(breaks=seq(0,300,50)) + geom_point()
```

Proportion overlapping low-mappability regions.

```{r novellm}
novel.reg$extlowmap = olProp(novel.reg, extlowmap.gr) >= .9
novel.reg$lowmap = olProp(novel.reg, lowmap.gr) >= .9
novel.reg %>% as.data.frame %>% summarize(region=n(), lowmap=mean(lowmap), extlowmap=mean(extlowmap)) %>% kable(digits=3)
```

### Novel regions in other CNV catalogs

```{r novelgs}
ol = findOverlaps(novel.reg, gs.hand) %>% as.data.frame %>% mutate(prop.samp=gs.hand$prop.samp[subjectHits]) %>% group_by(queryHits) %>% summarize(prop.samp=max(prop.samp))
novel.reg$max.freq.gs.hand = 0
novel.reg$max.freq.gs.hand[ol$queryHits] = ol$prop.samp

ol = findOverlaps(novel.reg, gs.chiang.samp) %>% as.data.frame %>% mutate(NSAMP=gs.chiang.samp$NSAMP[subjectHits]) %>% group_by(queryHits) %>% summarize(NSAMP=max(NSAMP))
novel.reg$max.freq.gs.chiang = 0
novel.reg$max.freq.gs.chiang[ol$queryHits] = ol$NSAMP / chiang.tot.samp

ol = findOverlaps(novel.reg, gonl.cnv) %>% as.data.frame %>% mutate(prop.samp=gonl.cnv$prop[subjectHits]) %>% group_by(queryHits) %>% summarize(prop.samp=max(prop.samp))
novel.reg$max.freq.gonl = 0
novel.reg$max.freq.gonl[ol$queryHits] = ol$prop.samp

novel.reg %>% as.data.frame %>% select(seqnames, start, end, max.freq.gs.chiang, max.freq.gs.hand, max.freq.gonl) %>% gather(catalog, prop.samp, 4:6) %>% ggplot(aes(prop.samp, colour=catalog)) + stat_ecdf() + theme_bw() + xlab('proportion of sample with an overlapping CNV') + ylab('cumulative proportion of novel CNV regions') + scale_colour_brewer(name='other CNV catalogs', labels=c('GoNL','Chiang 2018','Handsaker 2016'), palette='Set2') + theme(legend.position=c(.99,.01), legend.justification=c(1,0)) + scale_y_continuous(breaks=seq(0,1,.1))

novel.reg %>% as.data.frame %>% summarize(in.gs.handsaker=mean(max.freq.gs.hand>0), in.gs.chiang=mean(max.freq.gs.chiang>0), in.gonl=mean(max.freq.gonl>0)) %>% kable
```


## Frequency distribution in novel or low-mappability regions

```{r freqlowmap}
freq.df = rbind(
    cnv.ur %>% freq.range %>% mutate(cnv='all'),
    cnv.ur %>% filter(extlowmap) %>% freq.range %>% mutate(cnv='ext. low-mappability'),
    cnv.ur %>% filter(lowmap) %>% freq.range %>% mutate(cnv='low-mappability'),
    cnv.ur %>% filter(!tgp.ol) %>% freq.range %>% mutate(cnv='novel'))

freq.s = freq.df %>% mutate(cnv=factor(cnv, levels=c('all', 'novel', 'low-mappability', 'ext. low-mappability')), prop=round(prop,4)) %>% group_by(cnv, prop) %>% summarize(kb=sum((end-start+1)/1e3)) %>% arrange(desc(prop)) %>% mutate(prop.gen=kb/sum(kb), cumprop=cumsum(prop.gen))

ggplot(freq.s, aes(x=prop, y=cumprop, colour=cnv)) + geom_line(alpha=.9, size=2) + theme_bw() + ylim(0,1) + xlab("frequency") + ylab("cumulative proportion") + theme(legend.position=c(.99,.99),legend.justification=c(1,1)) + scale_colour_brewer(name="", palette="Set1") + scale_x_log10(breaks=c(.002,.005,.01,.02,.05,.1,.2,.5))
```


```{r paperout, echo=FALSE}
save(sum.df, sum.tgp.df, sum.gs.df, sum.gonl.df, merge.sum, cumfreq.popsv.tgp, chaisson.enr.df, pend.enr.df, chaisson.enr.s, pend.enr.s, novel.reg, freq.s, file='PopSV-catalog-overview.RData')
```
